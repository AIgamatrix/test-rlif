# requirements.txt records the full set of dependencies for development
accelerate
codetiming
datasets
dill
torch
flash-attn @ https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.0.post1/flash_attn-2.7.0.post1+cu12torch2.5cxx11abiFALSE-cp310-cp310-linux_x86_64.whl
hydra-core
liger-kernel
numpy
pandas
peft
pyarrow>=19.0.0
pybind11
pylatexenc
pre-commit
ray[default]
tensordict<=0.6.2
torchdata
transformers
# vllm==0.8.4
wandb
packaging>=20.0
uvicorn
fastapi
